# LinkedIn Posts Extractor por Keywords con Apify

Sistema de extracciÃ³n de posts de LinkedIn usando keywords con Apify, integrado con ClickUp para obtener keywords y guardar posts. **Solo busca posts de MÃ©xico.**

## CaracterÃ­sticas

- ğŸ” BÃºsqueda de posts de LinkedIn usando keywords con Apify Actor
- ğŸ‡²ğŸ‡½ Filtro de ubicaciÃ³n: Solo posts de MÃ©xico
- ğŸ”„ IntegraciÃ³n con ClickUp (obtener keywords desde lista y guardar posts)
- âœ… DetecciÃ³n de duplicados
- ğŸ“Š Rate limiting configurable (mÃ¡ximo de keywords por dÃ­a)
- â° Scheduler configurable (ejecuciÃ³n automÃ¡tica periÃ³dica)
- ğŸ“ Logging completo

## InstalaciÃ³n

```bash
# Ir a la carpeta backend
cd backend

# Instalar dependencias
npm install
```

## ConfiguraciÃ³n

Crea un archivo `.env` en la carpeta `backend` basÃ¡ndote en `.env.example`:

```env
# Apify Configuration
APIFY_API_TOKEN=tu_token_de_apify
APIFY_ACTOR_ID=buIWk2uOUzTmcLsuB

# ClickUp Configuration
CLICKUP_API_TOKEN=tu_token_de_clickup
CLICKUP_KEYWORDS_LIST_ID=901708915302
CLICKUP_POSTS_LIST_ID=901708915350

# Server Configuration
PORT=3004
NODE_ENV=development

# Rate Limiting
MAX_KEYWORDS_PER_DAY=10

# Posts Configuration
MAX_POSTS_PER_KEYWORD=20

# Scheduling Configuration (in minutes)
SCRAPE_INTERVAL_MINUTES=60

# Apify Actor Input Configuration
PROFILE_SCRAPER_MODE=short
START_PAGE=1
SCRAPE_REACTIONS=false
MAX_REACTIONS=5
SCRAPE_COMMENTS=false

# Location Filter (solo posts de MÃ©xico)
AUTHOR_LOCATION=Mexico

# Logging
LOG_LEVEL=INFO
```

### Variables de Entorno

#### Apify
- `APIFY_API_TOKEN`: Token de API de Apify (requerido)
- `APIFY_ACTOR_ID`: ID del Actor de Apify (por defecto: `buIWk2uOUzTmcLsuB`)

#### ClickUp
- `CLICKUP_API_TOKEN`: Token de API de ClickUp (requerido)
- `CLICKUP_KEYWORDS_LIST_ID`: ID de la lista de ClickUp donde estÃ¡n las keywords (por defecto: `901708915302`)
- `CLICKUP_POSTS_LIST_ID`: ID de la lista de ClickUp donde se guardarÃ¡n los posts (por defecto: `901708915350`)

#### Rate Limiting
- `MAX_KEYWORDS_PER_DAY`: MÃ¡ximo nÃºmero de keywords a procesar por dÃ­a (por defecto: `10`)

#### Posts Configuration
- `MAX_POSTS_PER_KEYWORD`: MÃ¡ximo nÃºmero de posts a extraer por keyword (por defecto: `20`)

#### Scheduling
- `SCRAPE_INTERVAL_MINUTES`: Intervalo en minutos entre ejecuciones automÃ¡ticas (por defecto: `60`)
  - `0` o no configurado: Deshabilita el scheduler

#### Apify Actor Input
- `PROFILE_SCRAPER_MODE`: Modo del scraper de perfiles (por defecto: `short`)
- `START_PAGE`: PÃ¡gina inicial (por defecto: `1`)
- `SCRAPE_REACTIONS`: Extraer reacciones (por defecto: `false`)
- `MAX_REACTIONS`: MÃ¡ximo nÃºmero de reacciones (por defecto: `5`)
- `SCRAPE_COMMENTS`: Extraer comentarios (por defecto: `false`)
- `AUTHOR_LOCATION`: UbicaciÃ³n del autor para filtrar (por defecto: `Mexico`) - Solo busca posts de MÃ©xico

## Uso

### OpciÃ³n 1: Servidor con Scheduler AutomÃ¡tico

```bash
# Ir a la carpeta backend
cd backend

# Iniciar servidor (el scheduler se iniciarÃ¡ automÃ¡ticamente si estÃ¡ configurado)
npm start
```

### OpciÃ³n 2: API REST

```bash
# Ir a la carpeta backend
cd backend

# Iniciar servidor
npm start

# Ejecutar scraping manualmente
curl -X POST http://localhost:3004/api/scraper/run-now

# Obtener estadÃ­sticas
curl http://localhost:3004/api/scraper/stats

# Buscar posts por keywords especÃ­ficas
curl -X POST http://localhost:3004/api/scraper/search-posts \
  -H "Content-Type: application/json" \
  -d '{
    "keywords": ["b2b sales", "marketing automation"]
  }'

# Buscar posts usando keywords de ClickUp
curl -X POST http://localhost:3004/api/scraper/search-posts \
  -H "Content-Type: application/json" \
  -d '{
    "useClickUp": true
  }'
```

### OpciÃ³n 3: Script de Prueba

```bash
# Ir a la carpeta backend
cd backend

# Ver estructura de datos (procesa 1 keyword)
npm run test-structure
```

## API Endpoints

### GET /health
Health check del servidor.

### POST /api/scraper/search-posts
Buscar posts por keywords.

**Request (con keywords):**
```json
{
  "keywords": ["b2b sales", "marketing automation"]
}
```

**Request (desde ClickUp):**
```json
{
  "useClickUp": true
}
```

### POST /api/scraper/run-now
Ejecutar scraping manualmente (usa keywords de ClickUp).

### GET /api/scraper/stats
Obtener estadÃ­sticas de rate limit y estado del scheduler.

## Flujo de Trabajo

1. **Obtener keywords desde ClickUp**: El sistema obtiene keywords desde una lista de ClickUp
2. **Verificar rate limit**: Se verifica si se puede procesar mÃ¡s keywords hoy
3. **Buscar posts con Apify**: Se usa el Actor de Apify para buscar posts con cada keyword
4. **Crear tareas en ClickUp**: Para cada post encontrado, se crea una tarea en ClickUp (si no es duplicado)
5. **Actualizar rate limit**: Se incrementa el contador de keywords procesadas

## Estructura del Proyecto

```
linkedin-posts-keywords-apify/
â””â”€â”€ backend/
    â”œâ”€â”€ controllers/
    â”‚   â””â”€â”€ scraperController.js
    â”œâ”€â”€ routes/
    â”‚   â””â”€â”€ scraperRoutes.js
    â”œâ”€â”€ services/
    â”‚   â”œâ”€â”€ apifyService.js
    â”‚   â”œâ”€â”€ clickupService.js
    â”‚   â”œâ”€â”€ loggerService.js
    â”‚   â”œâ”€â”€ rateLimitService.js
    â”‚   â””â”€â”€ schedulerService.js
    â”œâ”€â”€ scripts/
    â”‚   â”œâ”€â”€ scrape.js
    â”‚   â””â”€â”€ test-structure.js
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ logs/
    â”‚   â””â”€â”€ rate-limit.json
    â”œâ”€â”€ .env.example
    â”œâ”€â”€ package.json
    â”œâ”€â”€ server.js
    â””â”€â”€ README.md
```

## TecnologÃ­as

- **Node.js**: Runtime de JavaScript
- **Express**: Framework web
- **Apify Client**: Cliente para Apify Actors
- **Axios**: Cliente HTTP
- **node-cron**: Scheduler de tareas
- **dotenv**: GestiÃ³n de variables de entorno

## Licencia

ISC

# linkedin-posts-keywords-apify
