# LinkedIn Posts Extractor por Keywords con Apify

Sistema de extracci√≥n de posts de LinkedIn usando keywords con Apify, integrado con ClickUp para obtener keywords y HubSpot para crear deals. **Solo busca posts de M√©xico.**

## Caracter√≠sticas

- üîç B√∫squeda de posts de LinkedIn usando keywords con Apify Actor
- üá≤üáΩ Filtro de ubicaci√≥n: Solo posts de M√©xico
- üîÑ Integraci√≥n con ClickUp (obtener keywords desde lista)
- üíº Integraci√≥n con HubSpot (crear deals para cada post encontrado)
- ‚úÖ Detecci√≥n de duplicados
- üìä Rate limiting configurable (m√°ximo de keywords por d√≠a)
- ‚è∞ Scheduler configurable (ejecuci√≥n autom√°tica peri√≥dica)
- üìù Logging completo

## Instalaci√≥n

```bash
# Ir a la carpeta backend
cd backend

# Instalar dependencias
npm install
```

## Configuraci√≥n

Crea un archivo `.env` en la carpeta `backend` bas√°ndote en `.env.example`:

```env
# Apify Configuration
APIFY_API_TOKEN=tu_token_de_apify
APIFY_ACTOR_ID=buIWk2uOUzTmcLsuB

# ClickUp Configuration (solo para obtener keywords)
CLICKUP_API_TOKEN=tu_token_de_clickup
CLICKUP_KEYWORDS_LIST_ID=901708915302

# HubSpot Configuration (para crear deals)
HUBSPOT_TOKEN=tu_token_de_hubspot
HUBSPOT_DEAL_STAGE=appointmentscheduled
HUBSPOT_PIPELINE=default

# Server Configuration
PORT=3004
NODE_ENV=development

# Rate Limiting
MAX_KEYWORDS_PER_DAY=10

# Posts Configuration
MAX_POSTS_PER_KEYWORD=20

# Scheduling Configuration (in minutes)
SCRAPE_INTERVAL_MINUTES=60

# Apify Actor Input Configuration
PROFILE_SCRAPER_MODE=short
START_PAGE=1
SCRAPE_REACTIONS=false
MAX_REACTIONS=5
SCRAPE_COMMENTS=false

# Location Filter (solo posts de M√©xico)
AUTHOR_LOCATION=Mexico

# Logging
LOG_LEVEL=INFO
```

### Variables de Entorno

#### Apify
- `APIFY_API_TOKEN`: Token de API de Apify (requerido)
- `APIFY_ACTOR_ID`: ID del Actor de Apify (por defecto: `buIWk2uOUzTmcLsuB`)

#### ClickUp (solo para obtener keywords)
- `CLICKUP_API_TOKEN`: Token de API de ClickUp (requerido)
- `CLICKUP_KEYWORDS_LIST_ID`: ID de la lista de ClickUp donde est√°n las keywords (por defecto: `901708915302`)

#### HubSpot (para crear deals)
- `HUBSPOT_TOKEN`: Token de API de HubSpot (requerido)
- `HUBSPOT_PIPELINE_ID`: ID num√©rico del pipeline (opcional, por defecto: `811215668` - Pipeline "Prospecci√≥n")
- `HUBSPOT_DEAL_STAGE_ID`: ID num√©rico del stage (opcional, si no se especifica usa el primer stage del pipeline configurado)
  
  **Ejemplo de configuraci√≥n:**
  ```env
  HUBSPOT_PIPELINE_ID=811215668
  HUBSPOT_DEAL_STAGE_ID=1194313030  # "Hip√≥tesis OK" - primer stage del pipeline Prospecci√≥n
  ```
  
  **Stages disponibles en pipeline "Prospecci√≥n" (811215668):**
  - `1194313030` - Hip√≥tesis OK
  - `1195189302` - Apollo OK
  - `1195771750` - Invitando LI
  - `1194326274` - Email 1 OK
  - `1194326275` - Evento LI Creado
  - `1194326276` - Email 2 OK
  - `1194326277` - WhatsApp OK
  - `1194962947` - Llamada OK
  - `1194962948` - Email 3 OK
  - `1195344731` - Invitar en Zoom
  - `1195978305` - Descartado
  
  Para ver todos los stages disponibles, ejecuta: `npm run check-pipeline`

#### Rate Limiting
- `MAX_KEYWORDS_PER_DAY`: M√°ximo n√∫mero de keywords a procesar por d√≠a (por defecto: `10`)

#### Posts Configuration
- `MAX_POSTS_PER_KEYWORD`: M√°ximo n√∫mero de posts a extraer por keyword (por defecto: `20`)

#### Scheduling
- `SCRAPE_INTERVAL_MINUTES`: Intervalo en minutos entre ejecuciones autom√°ticas (por defecto: `60`)
  - `0` o no configurado: Deshabilita el scheduler

#### Apify Actor Input
- `PROFILE_SCRAPER_MODE`: Modo del scraper de perfiles (por defecto: `short`)
- `START_PAGE`: P√°gina inicial (por defecto: `1`)
- `SCRAPE_REACTIONS`: Extraer reacciones (por defecto: `false`)
- `MAX_REACTIONS`: M√°ximo n√∫mero de reacciones (por defecto: `5`)
- `SCRAPE_COMMENTS`: Extraer comentarios (por defecto: `false`)
- `AUTHOR_LOCATION`: Ubicaci√≥n del autor para filtrar (por defecto: `Mexico`) - Solo busca posts de M√©xico

## Uso

### Opci√≥n 1: Servidor con Scheduler Autom√°tico

```bash
# Ir a la carpeta backend
cd backend

# Iniciar servidor (el scheduler se iniciar√° autom√°ticamente si est√° configurado)
npm start
```

### Opci√≥n 2: API REST

```bash
# Ir a la carpeta backend
cd backend

# Iniciar servidor
npm start

# Ejecutar scraping manualmente
curl -X POST http://localhost:3004/api/scraper/run-now

# Obtener estad√≠sticas
curl http://localhost:3004/api/scraper/stats

# Buscar posts por keywords espec√≠ficas
curl -X POST http://localhost:3004/api/scraper/search-posts \
  -H "Content-Type: application/json" \
  -d '{
    "keywords": ["b2b sales", "marketing automation"]
  }'

# Buscar posts usando keywords de ClickUp
curl -X POST http://localhost:3004/api/scraper/search-posts \
  -H "Content-Type: application/json" \
  -d '{
    "useClickUp": true
  }'
```

### Opci√≥n 3: Script de Prueba

```bash
# Ir a la carpeta backend
cd backend

# Ver estructura de datos (procesa 1 keyword)
npm run test-structure
```

## API Endpoints

### GET /health
Health check del servidor.

### POST /api/scraper/search-posts
Buscar posts por keywords.

**Request (con keywords):**
```json
{
  "keywords": ["b2b sales", "marketing automation"]
}
```

**Request (desde ClickUp):**
```json
{
  "useClickUp": true
}
```

### POST /api/scraper/run-now
Ejecutar scraping manualmente (usa keywords de ClickUp).

### GET /api/scraper/stats
Obtener estad√≠sticas de rate limit y estado del scheduler.

## Flujo de Trabajo

1. **Obtener keywords desde ClickUp**: El sistema obtiene keywords desde una lista de ClickUp
2. **Verificar rate limit**: Se verifica si se puede procesar m√°s keywords hoy
3. **Buscar posts con Apify**: Se usa el Actor de Apify para buscar posts con cada keyword (solo de M√©xico)
4. **Crear deals en HubSpot**: Para cada post encontrado, se crea un deal en HubSpot (si no es duplicado)
5. **Actualizar rate limit**: Se incrementa el contador de keywords procesadas

### Informaci√≥n guardada en cada Deal de HubSpot

Cada deal incluye:
- **Nombre del deal**: `{Autor} - Post LinkedIn ({keyword})`
- **Descripci√≥n**: Contiene toda la informaci√≥n del post:
  - Keyword usada para encontrar el post
  - Autor/Perfil del post
  - URL del perfil de LinkedIn
  - URL del post
  - Contenido del post (primeros 1000 caracteres)
  - Fecha del post (si est√° disponible)
- **Pipeline y Stage**: Se obtienen autom√°ticamente del primer pipeline disponible (o el configurado en `.env`)
- **Monto**: 0 MXN (sin monto inicial)

**Nota**: Toda la informaci√≥n se guarda en la descripci√≥n del deal. Las propiedades personalizadas de LinkedIn no se crean autom√°ticamente, pero toda la informaci√≥n est√° disponible en la descripci√≥n.

## Estructura del Proyecto

```
linkedin-posts-keywords-apify/
‚îî‚îÄ‚îÄ backend/
    ‚îú‚îÄ‚îÄ controllers/
    ‚îÇ   ‚îî‚îÄ‚îÄ scraperController.js
    ‚îú‚îÄ‚îÄ routes/
    ‚îÇ   ‚îî‚îÄ‚îÄ scraperRoutes.js
    ‚îú‚îÄ‚îÄ services/
    ‚îÇ   ‚îú‚îÄ‚îÄ apifyService.js
    ‚îÇ   ‚îú‚îÄ‚îÄ clickupService.js
    ‚îÇ   ‚îú‚îÄ‚îÄ loggerService.js
    ‚îÇ   ‚îú‚îÄ‚îÄ rateLimitService.js
    ‚îÇ   ‚îî‚îÄ‚îÄ schedulerService.js
    ‚îú‚îÄ‚îÄ scripts/
    ‚îÇ   ‚îú‚îÄ‚îÄ scrape.js
    ‚îÇ   ‚îî‚îÄ‚îÄ test-structure.js
    ‚îú‚îÄ‚îÄ data/
    ‚îÇ   ‚îú‚îÄ‚îÄ logs/
    ‚îÇ   ‚îî‚îÄ‚îÄ rate-limit.json
    ‚îú‚îÄ‚îÄ .env.example
    ‚îú‚îÄ‚îÄ package.json
    ‚îú‚îÄ‚îÄ server.js
    ‚îî‚îÄ‚îÄ README.md
```

## Tecnolog√≠as

- **Node.js**: Runtime de JavaScript
- **Express**: Framework web
- **Apify Client**: Cliente para Apify Actors
- **Axios**: Cliente HTTP
- **node-cron**: Scheduler de tareas
- **dotenv**: Gesti√≥n de variables de entorno

## Licencia

ISC

# linkedin-posts-keywords-apify
# linkedin-posts-keywords-apify
